{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qmamnatividad/Midterm_Case_Study/blob/main/Midterm_Case_Study_Team_MaNiKa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUs3aRHkxcgF",
        "outputId": "6f37d8d6-04cf-4eb5-b8d8-abfe4a74fa1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrIR3Z4cCLjO",
        "outputId": "a44c707a-b4af-45b4-f8e2-7ad0b7ba6c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed aye.wav\n",
            "Processed andito.wav\n",
            "Processed cute naman.wav\n",
            "Processed gagsti.wav\n",
            "Processed hala!.wav\n",
            "Processed hoy diego.wav\n",
            "Processed hoy.wav\n",
            "Processed ito nga pala.wav\n",
            "Processed may magagawa.wav\n",
            "Processed nagsisilus din.wav\n",
            "Processed omsim!.wav\n",
            "Processed siya si diego.wav\n",
            "Processed yay.wav\n",
            "Audio processing complete.\n"
          ]
        }
      ],
      "source": [
        "# For Dora\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Define input and output directories\n",
        "input_dir = '/content/drive/MyDrive/Colab Notebooks/Midterm Exam - Team MaNiKa/Original Audio/RAW - WAV - dora'\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/Midterm Exam - Team MaNiKa/Modified Audio/MODIFIED - dora'\n",
        "\n",
        "# Define audio processing parameters\n",
        "pitch_shift_semitones = -10\n",
        "time_stretch_factor = 1.0  # Adjust to control time stretching\n",
        "low_pass_cutoff_hz = 5000  # Adjust the cutoff frequency as needed\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# List all WAV files in the input directory\n",
        "input_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
        "\n",
        "# Process each audio file\n",
        "for input_file in input_files:\n",
        "    # Construct full paths for input and output files\n",
        "    input_file_path = os.path.join(input_dir, input_file)\n",
        "    output_file_path = os.path.join(output_dir, input_file)\n",
        "\n",
        "    # Load the input audio file\n",
        "    audio, sr = librosa.load(input_file_path, sr=None)\n",
        "\n",
        "    # Apply pitch shifting\n",
        "    shifted_audio = librosa.effects.pitch_shift(audio, n_steps=pitch_shift_semitones, sr=sr)\n",
        "\n",
        "    # Apply time stretching\n",
        "    stretched_audio = signal.resample(shifted_audio, int(len(shifted_audio) * time_stretch_factor))\n",
        "\n",
        "    # Design a low-pass Butterworth filter\n",
        "    nyquist = 0.5 * sr\n",
        "    normal_cutoff = low_pass_cutoff_hz / nyquist\n",
        "    order = 6\n",
        "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
        "\n",
        "    # Apply the low-pass filter\n",
        "    filtered_audio = signal.filtfilt(b, a, stretched_audio)\n",
        "\n",
        "    # Save the processed audio as a WAV file\n",
        "    sf.write(output_file_path, filtered_audio, sr)\n",
        "\n",
        "    print(f\"Processed {input_file}\")\n",
        "\n",
        "print(\"Audio processing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Diego\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Define input and output directories\n",
        "input_dir = '/content/drive/MyDrive/Colab Notebooks/Midterm Exam - Team MaNiKa/Original Audio/RAW - WAV - diego'\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/Midterm Exam - Team MaNiKa/Modified Audio/MODIFIED - diego'\n",
        "\n",
        "# Define audio processing parameters\n",
        "pitch_shift_semitones = 5\n",
        "time_stretch_factor = 1.0  # Adjust to control time stretching\n",
        "low_pass_cutoff_hz = 5000  # Adjust the cutoff frequency as needed\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# List all WAV files in the input directory\n",
        "input_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
        "\n",
        "# Process each audio file\n",
        "for input_file in input_files:\n",
        "    # Construct full paths for input and output files\n",
        "    input_file_path = os.path.join(input_dir, input_file)\n",
        "    output_file_path = os.path.join(output_dir, input_file)\n",
        "\n",
        "    # Load the input audio file\n",
        "    audio, sr = librosa.load(input_file_path, sr=None)\n",
        "\n",
        "    # Apply pitch shifting\n",
        "    shifted_audio = librosa.effects.pitch_shift(audio, n_steps=pitch_shift_semitones, sr=sr)\n",
        "\n",
        "    # Apply time stretching\n",
        "    stretched_audio = signal.resample(shifted_audio, int(len(shifted_audio) * time_stretch_factor))\n",
        "\n",
        "    # Design a low-pass Butterworth filter\n",
        "    nyquist = 0.5 * sr\n",
        "    normal_cutoff = low_pass_cutoff_hz / nyquist\n",
        "    order = 6\n",
        "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
        "\n",
        "    # Apply the low-pass filter\n",
        "    filtered_audio = signal.filtfilt(b, a, stretched_audio)\n",
        "\n",
        "    # Save the processed audio as a WAV file\n",
        "    sf.write(output_file_path, filtered_audio, sr)\n",
        "\n",
        "    print(f\"Processed {input_file}\")\n",
        "\n",
        "print(\"Audio processing complete.\")"
      ],
      "metadata": {
        "id": "eI6k-hALnKK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8d156e-c338-4755-bc64-2b7da6f9e821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed ako rin.wav\n",
            "Processed angas.wav\n",
            "Processed ayyee geng geng.wav\n",
            "Processed di nya alam.wav\n",
            "Processed eto flex ko lang.wav\n",
            "Processed gusto nyo bang.wav\n",
            "Processed hoy.wav\n",
            "Processed if we all say (1).wav\n",
            "Processed if we all say (2).wav\n",
            "Processed naririnig mo ba.wav\n",
            "Processed naririnig niyo ba.wav\n",
            "Processed if we all say (3).wav\n",
            "Processed sa tingin nyo.wav\n",
            "Processed wala na.wav\n",
            "Processed binabackstab.wav\n",
            "Processed hi dora.wav\n",
            "Audio processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For Boots\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Define input and output directories\n",
        "input_dir = '/content/drive/MyDrive/Colab Notebooks/Midterm Exam - Team MaNiKa/Original Audio/RAW - WAV - boots'\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/Midterm Exam - Team MaNiKa/Modified Audio/MODIFIED - boots'\n",
        "\n",
        "# Define audio processing parameters\n",
        "pitch_shift_semitones = 10\n",
        "time_stretch_factor = 1.0  # Adjust to control time stretching\n",
        "low_pass_cutoff_hz = 5000  # Adjust the cutoff frequency as needed\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# List all WAV files in the input directory\n",
        "input_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
        "\n",
        "# Process each audio file\n",
        "for input_file in input_files:\n",
        "    # Construct full paths for input and output files\n",
        "    input_file_path = os.path.join(input_dir, input_file)\n",
        "    output_file_path = os.path.join(output_dir, input_file)\n",
        "\n",
        "    # Load the input audio file\n",
        "    audio, sr = librosa.load(input_file_path, sr=None)\n",
        "\n",
        "    # Apply pitch shifting\n",
        "    shifted_audio = librosa.effects.pitch_shift(audio, n_steps=pitch_shift_semitones, sr=sr)\n",
        "\n",
        "    # Apply time stretching\n",
        "    stretched_audio = signal.resample(shifted_audio, int(len(shifted_audio) * time_stretch_factor))\n",
        "\n",
        "    # Design a low-pass Butterworth filter\n",
        "    nyquist = 0.5 * sr\n",
        "    normal_cutoff = low_pass_cutoff_hz / nyquist\n",
        "    order = 6\n",
        "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
        "\n",
        "    # Apply the low-pass filter\n",
        "    filtered_audio = signal.filtfilt(b, a, stretched_audio)\n",
        "\n",
        "    # Save the processed audio as a WAV file\n",
        "    sf.write(output_file_path, filtered_audio, sr)\n",
        "\n",
        "    print(f\"Processed {input_file}\")\n",
        "\n",
        "print(\"Audio processing complete.\")"
      ],
      "metadata": {
        "id": "oUOx5G6unUVy",
        "outputId": "2c19df4f-be76-4aad-8e5d-9e18b8330df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed YAAY.wav\n",
            "Processed WOWW MAGKAMUKHA.wav\n",
            "Processed teka lang hayop.wav\n",
            "Processed sino yon.wav\n",
            "Processed di natin sure.wav\n",
            "Processed aye aye aye.wav\n",
            "Processed ikaw ba yan kuya.wav\n",
            "Processed makukulit talaga ang.wav\n",
            "Processed mekus mekus.wav\n",
            "Processed at ako si boots.wav\n",
            "Audio processing complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}